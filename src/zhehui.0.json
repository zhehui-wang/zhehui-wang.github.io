var zhehui = [
      {
      "type": "Journal",
      "title": "Optimizing for In-memory Deep Learning with Emerging Memory Technology ",
      "author": "Zhehui Wang, Tao Luo, Rick Siow Mong Goh, Wei Zhang, Weng-Fai Wong;", 
      "source": "IEEE Transactions on Neural Networks and Learning Systems (TNNLS)",
      "info": "accepted, 2023",
      "abstract": "In-memory deep learning executes neural network models where they are stored, thus avoiding long-distance communication between memory and computation units, resulting in considerable savings in energy and time. In-memory deep learning has already demonstrated orders of magnitude higher performance density and energy efficiency. The use of emerging memory technology promises to increase density, energy, and performance even further. However, emerging memory technology is intrinsically unstable, resulting in random data read fluctuations. This can translate to non-negligible accuracy loss, potentially nullifying the gains. In this paper, we propose three optimization techniques that can mathematically overcome the instability problem of emerging memory technology. They can improve the accuracy of the in-memory deep learning model while maximizing its energy efficiency. Experiments show that our solution can fully recover most models' state-of-the-art accuracy, and achieves at least an order of magnitude higher energy efficiency than the state-of-the-art.",
      "bibtex": " "
    }, 
    {
      "type": "Journal",
      "title": "Efficient Spiking Neural Networks with Radix Encoding",
      "author": "Zhehui Wang, Xiaozhe Gu, Rick Siow Mong Goh, Joey Tianyi Zhou, Tao Luo;", 
      "source": "IEEE Transactions on Neural Networks and Learning Systems (TNNLS)",
      "info": "Early Access, 2022",
      "abstract": "Spiking neural networks (SNNs) have advantages in latency and energy efficiency over traditional artificial neural networks (ANNs) due to their event-driven computation mechanism and the replacement of energy-consuming weight multiplication with addition. However, to achieve high accuracy, it usually requires long spike trains to ensure accuracy, usually more than 1000 time steps. This offsets the computation efficiency brought by SNNs because a longer spike train means a larger number of operations and larger latency. In this article, we propose a radix-encoded SNN, which has ultrashort spike trains. Specifically, it is able to use less than six time steps to achieve even higher accuracy than its traditional counterpart. We also develop a method to fit our radix encoding technique into the ANN-to-SNN conversion approach so that we can train radix-encoded SNNs more efficiently on mature platforms and hardware. Experiments show that our radix encoding can achieve 25 × improvement in latency and 1.7% improvement in accuracy compared to the state-of-the-art method using the VGG-16 network on the CIFAR-10 dataset.",
      "bibtex": "@ARTICLE{9856616,\nauthor={Wang, Zhehui and Gu, Xiaozhe and Goh, Rick Siow Mong and Zhou, Joey Tianyi and Luo, Tao},\njournal={IEEE Transactions on Neural Networks and Learning Systems},\ntitle={Efficient Spiking Neural Networks With Radix Encoding},\nyear={2022},\nvolume={},\nnumber={},\npages={1-13}}"
    }, 
    {
      "type": "Journal",
      "title": "EDCompress: Energy-Aware Model Compression for Dataflows",
      "author": "Zhehui Wang, Tao Luo, Rick Siow Mong Goh, Joey Tianyi Zhou;", 
      "source": "IEEE Transactions on Neural Networks and Learning Systems (TNNLS)",
      "info": "Early Access, 2022",
      "abstract": "Edge devices demand low energy consumption, cost, and small form factor. To efficiently deploy convolutional neural network (CNN) models on the edge device, energy-aware model compression becomes extremely important. However, existing work did not study this problem well because of the lack of considering the diversity of dataflow types in hardware architectures. In this article, we propose EDCompress (EDC), an energy-aware model compression method for various dataflows. It can effectively reduce the energy consumption of various edge devices, with different dataflow types. Considering the very nature of model compression procedures, we recast the optimization process to a multistep problem and solve it by reinforcement learning algorithms. We also propose a multidimensional multistep (MDMS) optimization method, which shows higher compressing capability than the traditional multistep method. Experiments show that EDC could improve 20x, 17x, and 26x energy efficiency in VGG-16, MobileNet, and LeNet-5 networks, respectively, with negligible loss of accuracy. EDC could also indicate the optimal dataflow type for specific neural networks in terms of energy consumption, which can guide the deployment of CNN on hardware.",
      "bibtex": "@ARTICLE{9774840,\nauthor={Wang, Zhehui and Luo, Tao and Goh, Rick Siow Mong and Zhou, Joey Tianyi},\njournal={IEEE Transactions on Neural Networks and Learning Systems},\ntitle={EDCompress: Energy-Aware Model Compression for Dataflows},\nyear={2022},\nvolume={},\nnumber={},\npages={1-13}}"
    }, 
    {
      "type": "Journal",
      "title": "Evolutionary Multi-Objective Model Compression for Deep Neural Networks",
      "author": "Zhehui Wang, Tao Luo, Miqing Li, Joey Tianyi Zhou, Rick Siow Mong Goh, Liangli Zhen;", 
      "source": "IEEE Computational Intelligence Magazine (CIM)",
      "info": "vol. 16, no. 3, pp. 10-21, Aug. 2021",
      "abstract": "While deep neural networks (DNNs) deliver state-of-the-art accuracy on various applications from face recognition to language translation, it comes at the cost of high computational and space complexity, hindering their deployment on edge devices. To enable efficient processing of DNNs in inference, a novel approach, called Evolutionary Multi-Objective Model Compression (EMOMC), is proposed to optimize energy efficiency (or model size) and accuracy simultaneously. Specifically, the network pruning and quantization space are explored and exploited by using architecture population evolution. Furthermore, by taking advantage of the orthogonality between pruning and quantization, a two-stage pruning and quantization co-optimization strategy is developed, which considerably reduces time cost of the architecture search. Lastly, different dataflow designs and parameter coding schemes are considered in the optimization process since they have a significant impact on energy consumption and the model size. Owing to the cooperation of the evolution between different architectures in the population, a set of compact DNNs that offer trade-offs on different objectives (e.g., accuracy, energy efficiency and model size) can be obtained in a single run. Unlike most existing approaches designed to reduce the size of weight parameters with no significant loss of accuracy, the proposed method aims to achieve a trade-off between desirable objectives, for meeting different requirements of various edge devices. Experimental results demonstrate that the proposed approach can obtain a diverse population of compact DNNs that are suitable for a broad range of different memory usage and energy consumption requirements. Under negligible accuracy loss, EMOMC improves the energy efficiency and model compression rate of VGG-16 on CIFAR-10 by a factor of more than 8.9 X and 2.4 X, respectively.",
      "bibtex": "@ARTICLE{9492169,\nauthor={Wang, Zhehui and Luo, Tao and Li, Miqing and Zhou, Joey Tianyi and Goh, Rick Siow Mong and Zhen, Liangli},\njournal={IEEE Computational Intelligence Magazine},\ntitle={Evolutionary Multi-Objective Model Compression for Deep Neural Networks},\nyear={2021},\nvolume={16},\nnumber={3},\npages={10-21}}"
    }, 
    {
      "type": "Journal",
      "title": "Reduce Loss and Crosstalk in Integrated Silicon-Photonic Multistage Switching Fabrics through Multi-Chip Partition",
      "author": "Zhehui Wang, Zhifei Wang, Jiang Xu, Jun Feng, Shixi Chen, Xuanqi Chen, Jiaxu Zhang;", 
      "source": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD)",
      "info": "vol. 40, no. 1, pp. 101-114, Jan. 2021",
      "abstract": "With the increasing popularity of data-intensive applications in data centers, the switching fabric in the internode network becomes significant. Silicon-photonic switching fabrics have a bright future in data centers, which offer high bandwidth, high energy efficiency, and low latency. However, integrating a high radix multistage switching fabric in a single chip faces challenges. A large number of waveguide crossings on the silicon photonic die causes massive power loss and introduces a tremendous amount of crosstalk noise. In this article, we propose a chip partition optimization platform (POP), which can decrease the number of waveguide crossings and shorten the on-chip traversal distance of optical signals. Our algorithms can effectively reduce the power loss and crosstalk noise in silicon-photonic multistage switching fabrics, and help to improve the signal integrity. For example, compared with the common design, POP can achieve 33-dB improvement on average power loss, 42-dB improvement on the worst-case power loss, and 39-dB improvement on the worst-case signal to noise ratio, in a 1024×1024 butterfly based silicon-photonic switching fabric.",
      "bibtex": "@ARTICLE{9089039,\nauthor={Wang, Zhehui and Wang, Zhifei and Xu, Jiang and Feng, Jun and Chen, Shixi and Chen, Xuanqi and Zhang, Jiaxu},\njournal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},\ntitle={Reduce Loss and Crosstalk in Integrated Silicon-Photonic Multistage Switching Fabrics Through Multichip Partition},\nyear={2021},\nvolume={40},\nnumber={1},\npages={101-114}}"
    },
    {
      "type": "Journal",
      "title": "CAMON: Low-Cost Silicon Photonic Chiplet for Manycore Processors",
      "author": "Zhehui Wang, Zhifei Wang, Jiang Xu, Yi-Shing Chang, Jun Feng, Xuanqi Chen, Shixi Chen, Jiaxu Zhang;",
      "source": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD)",
      "info": "vol. 39, no. 9, pp. 1820-1833, Sept. 2020",
      "abstract": "While many new applications prefer manycore processor with a large number of cores, the exploding communications among multiple cores, caches, and off-chip memories is posing a fundamental challenge on manycore designs. Silicon photonics based interconnection network promises high bandwidth, low latency, and high energy efficiency, and can potentially meet the communication requirements of manycore processors. In this work, we propose CAMON, a small low-cost silicon photonic chiplet integrated into the manycore processor package. CAMON chiplet can effectively alleviate the communication bottlenecks of manycore processors and improve the energy efficiency of data movement, especially for large-scale systems. We develop a distributed arbitration system, a low-power low-latency optical interface, and an off-chip laser preactivation mechanism for CAMON. Experiment results show that compared with the electrical network, CAMON can improve the full-system performance per energy by 4.6X, speed up the manycore processor by 2.7X, and save the area of the processor die by 3%, in a 512-core system.",
      "bibtex": "@ARTICLE{8755274,\nauthor={Wang, Zhehui and Wang, Zhifei and Xu, Jiang and Chang, Yi-Shing and Feng, Jun and Chen, Xuanqi and Chen, Shixi and Zhang, Jiaxu},\njournal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},\ntitle={CAMON: Low-Cost Silicon Photonic Chiplet for Manycore Processors},\nyear={2020},\nvolume={39},\nnumber={9},\npages={1820-1833}}"
    }, 
    {
      "type": "Journal",
      "title": "A Holistic Modeling and Analysis of Optical-Electrical Interfaces for Inter/Intra-chip Interconnects",
      "author": "Zhehui Wang, Jiang Xu, Peng Yang, Luan H.K. Duong, Zhifei Wang, Xuan Wang, Zhe Wang, Haoran Li, Rafael K.V. Maeda;",
      "source": "IEEE Transactions on Very Large Scale Integration Systems (TVLSI)",
      "info": "vol. 24, no. 7, pp. 2462-2474, July 2016",
      "abstract": "With the fast development of processor chips, power-efficient, high-bandwidth, and low-latency interchip interconnects become more and more important. Studies show that the bandwidth of traditional parallel interconnects with low I/O clock frequencies will become bottlenecks in the near future. To solve this problem, two types of high-bandwidth interchip interconnects are developed. Low-swing differential electrical interconnects have widely been used in high-speed I/O designs. On the other hand, optical interconnects promise high bandwidth, low latency, and could improve the chip pin performance for manycore processors. They are becoming potential alternatives for electrical interconnects. This paper systematically models these two types of interconnects in terms of crosstalk noises, attenuation, and receiver sensitivities. Based on the proposed models, we developed optical and electrical interfaces and links (OEIL) and an analysis tool for OEIL. The OEIL can be used to analyze the energy consumption, bandwidth density, and latency of interconnects. Analytical models are verified by the results of published experiments. It shows that the optical interconnects have much higher bandwidth densities than the electrical interconnects. With this feature, the optical interconnects can significantly reduce I/O pin count compared with the electrical interconnects. For example, they can save at least 92% signal pins when connecting chips more than 25 cm (10 in) apart. The energy consumption of optical interconnects is comparable with that of electrical interconnects, and the latency of polymer waveguide-based optical interconnects is 18% less than that of electrical interconnect.",
      "bibtex": "@ARTICLE{7389433,\nauthor={Wang, Zhehui and Xu, Jiang and Yang, Peng and Duong, Luan Huu Kinh and Wang, Zhifei and Wang, Xuan and Wang, Zhe and Li, Haoran and Maeda, Rafael Kioji Vivas},\njournal={IEEE Transactions on Very Large Scale Integration (VLSI) Systems},\ntitle={A Holistic Modeling and Analysis of Optical–Electrical Interfaces for Inter/Intra-chip Interconnects},\nyear={2016},\nvolume={24},\nnumber={7},\npages={2462-2474}}"
    },   
    {
      "type": "Journal",
      "title": "Improve Chip Pin Performance Using Optical Interconnects",
      "author": "Zhehui Wang, Jiang Xu, Peng Yang, Xuan Wang, Zhe Wang, Luan H.K. Duong, Zhifei Wang, Rafael K.V. Maeda, Haoran Li;",
      "source": "IEEE Transactions on Very Large Scale Integration Systems (TVLSI)",
       "info": "vol. 24, no. 4, pp. 1574-1587, April 2016",
      "abstract": "With the fast development of inter/intra-chip optical interconnects, the gap between the data rates of electrical interconnects and optical interconnects is continuously increasing. Electrical-optical (E-O) interfaces and optical-electrical (O-E) interfaces are a pair of components that convert data between parallel electrical interconnects and serial optical interconnects. This paper holistically models and analyzes E-O and O-E interfaces in terms of energy consumption, area, and latency. Traditional interfaces, where data are converted between parallel and serial ports by serializers and deserializers (SerDes), are studied. A new type of E-O and O-E interface, which serializes and deserializes data by optical weaving technologies, are proposed alongside. Traditional interfaces will become a bottleneck for the further development of optical interconnects in the near future because of the high energy consumption and large area of SerDes necessitating new technologies. Our analysis shows that optical weaving interfaces have a better overall performance than traditional interfaces. For example, if there are 64 parallel electrical interconnects and four optical wavelengths, optical weaving interfaces can achieve a 81.6% improvement in energy consumption and a 40.8% improvement in area, compared with traditional interfaces.",
      "bibtex": "@ARTICLE{7154512,\nauthor={Wang, Zhehui and Xu, Jiang and Yang, Peng and Wang, Xuan and Wang, Zhe and Duong, Luan Huu Kinh and Wang, Zhifei and Maeda, Rafael Kioji Vivas and Li, Haoran},\njournal={IEEE Transactions on Very Large Scale Integration (VLSI) Systems},\ntitle={Improve Chip Pin Performance Using Optical Interconnects},\nyear={2016},\nvolume={24},\nnumber={4},\npages={1574-1587}}"
    },  
    {
      "type": "Journal",
      "title": "Floorplan Optimization of Fat-Tree Based Networks-on-Chip for Chip Multiprocessors",
      "author": "Zhehui Wang, Jiang Xu, Xiaowen Wu, Yaoyao Ye, Wei Zhang, Mahdi Nikdast, Xuan Wang, Zhe Wang;",
      "source": "IEEE Transactions on Computers (TC)",
      "info": "vol. 63, no. 6, pp. 1446-1459, June 2014", 
      "abstract": "Chip multiprocessor (CMP) is becoming increasingly popular in the processor industry. Efficient network-on-chip (NoC) that has similar performance to the processor cores is important in CMP design. Fat-tree-based on-chip network has many advantages over traditional mesh or torus-based networks in terms of throughput, power efficiency, and latency. It has a bright future in the development of CMP. However, the floorplan design of the fat-tree-based NoC is very challenging because of the complexity of topology. There are a large number of crossings and long interconnects, which cause severe performance degradation in the network. In electronic NoCs, the parasitic capacitance and inductance will be significant. In optical ones, large crosstalk noise and power loss will be introduced. The novel contribution of this paper is to propose a method to optimize the fat-tree floorplan, which can effectively reduce the number of crossings and minimize the interconnect length. Two types of floorplans are proposed, which could be applied to fat-tree-based networks of arbitrary size. Compared with the traditional one, our floorplans could reduce more than 87% of the crossings. Since the traversal distance for signals is related to the aspect ratio of the processor cores, we also present a method to calculate the optimum aspect ratio of the processor cores to minimize the traversal distance.",
      "bibtex": "@ARTICLE{6392822,\nauthor={Wang, Zhehui and Xu, Jiang and Wu, Xiaowen and Ye, Yaoyao and Zhang, Wei and Nikdast, Mahdi and Wang, Xuan and Wang, Zhe},\njournal={IEEE Transactions on Computers},\ntitle={Floorplan Optimization of Fat-Tree-Based Networks-on-Chip for Chip Multiprocessors},\nyear={2014},\nvolume={63},\nnumber={6},\npages={1446-1459}}"
    },  
    {
      "type": "Conference",
      "title": "NCPower: Power Modelling for NVM-based Neuromorphic Chip",
      "author": "Zhehui Wang, Huaipeng Zhang, Tao Luo, Weng-Fai Wong, Anh Tuan Do, Paramasivam Vishnu, Wei Zhang, Rick Siow Mong Goh;",
      "source": "International Conference on Neuromorphic Systems (ICONS)",
      "info": "Article 15, 1–7, July 2020",
      "abstract": "Spiking neural networks (SNN) on non-volatile nemory (NVM) based neuromorphic computing (NC) chips have been regarded as a promising solution in power constrained scenarios, such as Internet of Things (IoT), due to its low energy consumption. The high power efficiency of NC is due to various aspects including the non-von Neumann architecture of NC chip, low power NVM, and the event-driven computation of SNN etc., and introduces a large space for low power design exploration. Therefore, a comprehensive quantitative study of the power modelling for such neuromorphic computing system is important for low power design. In this work, we propose NCPower, an energy consumption estimator for NVM-based neuromorphic chip. We systemically developed analytical models for each module in the chip based on physical laws. We verified NCPower by comparing the analytical results with measurement results from different NVM based neuromorphic chips. The analytical result from NCPower could well match experiment results. We integrated NCPower in a SNN simulator, and analyzed the accuracy and energy consumption of both the traditional multi-spike based SNN and the novel single-spike based SNN. It shows that the single-spike model has 7X energy efficiency over the multi-spike model, while maintaining a similar accuracy under the CIFAR10 dataset. The estimator also showed that the best resistance range for the NVM resistors is 10 kOmega-100 kOmega for the multi-spike model.",
      "bibtex": "@inproceedings{10.1145/3407197.3407619,\nauthor = {Wang, Zhehui and Zhang, Huaipeng and Luo, Tao and Wong, Weng-Fai and Do, Anh Tuan and Vishnu, Paramasivam and Zhang, Wei and Goh, Rick Siow Mong},\ntitle = {NCPower: Power Modelling for NVM-Based Neuromorphic Chip},\nyear = {2020},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nbooktitle = {International Conference on Neuromorphic Systems 2020},\narticleno = {15},\nnumpages = {7},\nlocation = {Oak Ridge, TN, USA},\nseries = {ICONS 2020}}"
    }, 
    {
      "type": "Conference",
      "title": "MOCA: an Inter/Intra-Chip Optical Network for Memory",
      "author": "Zhehui Wang, Zhengbin Pang, Peng Yang, Jiang Xu, Xuanqi Chen, Rafael K.V. Maeda, Zhifei Wang, Luan H.K. Duong, Haoran Li, Zhe Wang;",
      "source": "Design Automation Conference (DAC)",
      "info": "pp. 1-6, June 2017",
      "abstract": "The memory wall problem is due to the imbalanced developments and separation of processors and memories. It is becoming acute as more and more processor cores are integrated into a single chip and demand higher memory bandwidth through limited chip pins. Optical memory interconnection network (OMIN) promises high bandwidth, bandwidth density, and energy efficiency, and can potentially alleviate the memory wall problem. In this paper, we propose an optical inter/intra-chip processor-memory communication architecture, called MOCA. Experimental results and analysis show that MOCA can significantly improve system performance and energy efficiency. For example, comparing to Hybrid Memory Cube (HMC), MOCA can speedup application execution time by 2.6×, reduce communication latency by 75%, and improve energy efficiency by 3.4× for 256-core processors in 7 nm technology.",
      "bibtex": "@INPROCEEDINGS{8060369,\nauthor={Wang, Zhehui and Pang, Zhengbin and Yang, Peng and Xu, Jiang and Chen, Xuanqi and Maeda, Rafael Kioji Vivas and Wang, Zhifei and Duong, Luan Huu Kinh and Li, Haoran and Wang, Zhe},\nbooktitle={2017 54th ACM/EDAC/IEEE Design Automation Conference (DAC)},\ntitle={MOCA: An inter/intra-chip optical network for memory},\nyear={2017},\nvolume={},\nnumber={}, \npages={1-6}}"
    }, 
    {
      "type": "Conference",
      "title": "Alleviate Chip I/O Pin Constraints for Multicore Processors Through Optical Interconnects",
      "author": "Zhehui Wang, Jiang Xu, Peng Yang, Xuan Wang, Zhe Wang, Luan H.K Duong, Zhifei Wang, Haoran Li, Rafael K.V. Maeda, Xiaowen Wu, Yaoyao Ye, Qinfen Hao </I>;",
      "source": "Asia and South Pacific Design Automation Conference (ASP-DAC)",
      "info": "pp. 791-796, Jan. 2015",
      "abstract": "Chip I/O pins are an increasingly limited resource and significantly affect the performance, power and cost of multicore processors. Optical interconnects promise low power and high bandwidth, and are potential alternatives to electrical interconnects. This work systematically developed a set of analytical models for electrical and optical interconnects to study their structures, receiver sensitivities, crosstalk noises, and attenuations. We verified the models by published implementation results. The analytical models quantitatively identified the advantages of optical interconnects in terms of bandwidth, energy consumption, and transmission distance. We showed that optical interconnects can significantly reduce chip pin counts. For example, compared to electrical interconnects, optical interconnects can save at least 92% signal pins when connecting chips more than 25 cm (10 inches) apart.",
      "bibtex": "@INPROCEEDINGS{7059107,\nauthor={Wang, Zhehui and Xu, Jiang and Yang, Peng and Wang, Xuan and Wang, Zhe and Duong, Luan Huu Kinh and Wang, Zhifei and Li, Haoran and Maeda, Rafael Kioji Vivas and Wu, Xiaowen and Ye, Yaoyao and Hao, Qinfen},\nbooktitle={The 20th Asia and South Pacific Design Automation Conference},\ntitle={Alleviate chip I/O pin constraints for multicore processors through optical interconnects},\nyear={2015},\nvolume={},\nnumber={},\npages={791-796}}"
    },
    {
      "type": "Conference",      
      "title": "A Novel Low-Waveguide-Crossing Floorplan for Fat Tree Based Optical Networks-on-Chip",
      "author": "Zhehui Wang, Jiang Xu, Xiaowen Wu, Yaoyao Ye, Wei Zhang, Weichen Liu, Mahdi Nikdast, Xuan Wang, Zhe Wang;",
      "source": "IEEE Optical Interconnects Conference (OI)",
      "info": "pp. 100-101, May 2012",
      "abstract": "Optical network-on-chip (ONoC) can be used as the communication backbone for high performance chip multiprocessors (CMPs). Fat tree based ONoC shows high throughput, small delay and low power consumption. However, the traditional floorplan design of fat tree based ONoC has a large number of waveguide crossings because of the fat tree topology. In this paper, we present an optimized floorplan with the least number of waveguide crossings that has been reported. The average number of waveguide crossings per optical path in the optimized floorplan is 87% less than that in traditional floorplan for a 64-core CMP. We also find the optimal aspect ratio of cores to minimize the end-to-end delay. These work could help to ease the physical implementation of fat tree based ONoC for CMP.",
      "bibtex": "@INPROCEEDINGS{6224427,\nauthor={Wang, Zhehui and Xu, Jiang and Wu, Xiaowen and Ye, Yaoyao and Zhang, Wei and Liu, Weichen and Nikdast, Mahdi and Wang, Xuan and Wang, Zhe},\nbooktitle={2012 Optical Interconnects Conference}, \ntitle={A novel low-waveguide-crossing floorplan for fat tree based optical networks-on-chip}, \nyear={2012},\nvolume={},\nnumber={},\npages={100-101}}"
    },    
    {
      "type": "Book",
      "title": "Silicon Photonics Enabled Rack-Scale Many-Core Systems",
      "author": "Peng Yang, Zhehui Wang, Zhifei Wang, Xuanqi Chen, Luan H. Duong, Jiang Xu;",
      "source": "Many-Core Computing: Hardware and Software",
      "info": "pp. 449-470, June 2019",
      "abstract": "The increasingly higher demands on computing power from scientific computations, big data processing and deep learning are pushing the emergence of exascale computing systems. Tens of thousands of or even more manycore nodes are connected to build such systems. It imposes huge performance and power challenges on different aspects of the systems. As a basic block in high-performance computing systems, modularized rack will play a significant role in addressing these challenges. In this chapter, we introduce rack-scale optical networks (RSON), a silicon photonics enabled inter/intra-chip network for rack-scale many-core systems. RSON leverages the fact that most traffic is within rack and the high bandwidth and low-latency rack-scale optical network can improve both performance and energy efficiency. We codesign the intra-chip and inter-chip optical networks together with optical internode interface to provide balanced data access to both local memory and remote note's memory, making the nodes within rack cooperate effectively. The evaluations show that RSON can improve the overall performance and energy efficiency dramatically. Specifically, RSON can deliver as much as 5.4x more performance under the same energy consumption compared to traditional InfiniBand connected rack.",
      "bibtex": "@CHAPTER{PengYang2019,\nauthor={Yang, Peng and Wang, Zhehui and Wang, Zhifei and Chen, Xuanqi and Duong, Luan Huu Kinh and Xu, Jiang},\ntitle={Silicon photonics enabled rack-scale many-core systems},\nbooktitle=Many-Core Computing: Hardware and Software,\npublisher={Institution of Engineering and Technology},\nyear={2019},\npages={449-470},\nseries={Computing},\ndoi={10.1049/PBPC022E_ch18}}"
    }, 
    {
      "type": "Book",
      "title": "A Fast Joint Application-Architecture Exploration Platform for Heterogeneous Systems",
      "author": "Rafael K. V. Maeda, Peng Yang, Haoran Li, Zhongyuan Tian, Zhehui Wang, Zhifei Wang, Xuanqi Chen, Jun Feng, Jiang Xu;",
      "source": "Embedded, Cyber-Physical, and IoT Systems",
      "info": "pp. 203-232, Jan 2020",
      "abstract": "Computing systems become increasingly heterogeneous by adopting domain-specific accelerators. While heterogeneity provides better trade-offs among performance, energy efficiency, and cost, it adds new dimensions to the already huge design space. Existing design exploration tools rely on time-based analysis. Simulating a heterogeneous computing system using detailed cycle-accurate simulations could last for months, if not years. In this work, we introduce JADE, a joint application-architecture exploration platform for heterogeneous computing systems. JADE targets design space explorations with overall system characteristics such as average performance and energy efficiency instead of detailed cycle-by-cycle behaviors. It uses statistical application models and cycle-accurate architecture models. JADE can speed up design explorations by several orders of magnitude. The statistical application behaviors make it easy to explore heterogeneous systems. JADE can simulate complete systems including processing units, memory hierarchy, interconnect, and peripherals.",
      "bibtex": "@Inbook{VivasMaeda2020,\nauthor={Maeda, Rafael Kioji Vivas and Yang, Peng and Li, Haoran and Tian, Zhongyuan and Wang, Zhehui and Wang, Zhifei and Chen, Xuanqi and Feng, Jun and Xu, Jiang},\neditor={Bhattacharyya, Shuvra S. and Potkonjak, Miodrag and Velipasalar, Senem},\ntitle={A Fast Joint Application-Architecture Exploration Platform for Heterogeneous Systems},\nbookTitle={Embedded, Cyber-Physical, and IoT Systems: Essays Dedicated to Marilyn Wolf on the Occasion of Her 60th Birthday},\nyear={2020},\npublisher={Springer International Publishing},\naddress={Cham},\npages={203--232},\nisbn={978-3-030-16949-7},\ndoi={10.1007/978-3-030-16949-7_9}}"
    },  
  ]
